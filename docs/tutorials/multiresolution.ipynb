{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Resolution Modeling\n",
    "\n",
    "This tutorial shows how to model sources frome images observed with different telescopes. We will use a multiband observation with the Hyper-Sprime Cam (HSC) and a single high-resolution image from the Hubble Space Telescope (HST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "from scarlet.numeric import np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "from scarlet.display import AsinhMapping\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We first load the HSC and HST images, swapping the byte order if necessary because a bug in astropy does not respect the local endianness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HSC image data\n",
    "obs_hdu = fits.open('../../data/test_resampling/Cut_HSC.fits')\n",
    "data_hsc = obs_hdu[0].data.byteswap().newbyteorder()\n",
    "wcs_hsc = WCS(obs_hdu[0].header)\n",
    "channels_hsc = ['g','r','i','z','y']\n",
    "\n",
    "# Load the HSC PSF data\n",
    "psf_hsc = fits.open('../../data/test_resampling/PSF_HSC.fits')[0].data\n",
    "Np1, Np2 = psf_hsc[0].shape\n",
    "psf_hsc = scarlet.PSF(psf_hsc)\n",
    "\n",
    "# Load the HST image data\n",
    "hst_hdu = fits.open('../../data/test_resampling/Cut_HST.fits')\n",
    "data_hst = hst_hdu[0].data\n",
    "wcs_hst = WCS(hst_hdu[0].header)\n",
    "channels_hst = ['F814W']\n",
    "\n",
    "# apply wcs correction\n",
    "#wcs_hst.wcs.crval -= 2.4750118475607095e-05*np.array([0,1])\n",
    "# Load the HST PSF data\n",
    "psf_hst = fits.open('../../data/test_resampling/PSF_HST.fits')[0].data\n",
    "psf_hst = psf_hst[None,:,:]\n",
    "psf_hst = scarlet.PSF(psf_hst)\n",
    "\n",
    "# Scale the HST data\n",
    "n1,n2 = data_hst.shape\n",
    "data_hst = data_hst.reshape(1, n1, n2).byteswap().newbyteorder()\n",
    "\n",
    "r, N1, N2 = data_hsc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to create a source catalog for the images. We'll use `sep` for that, but any other detection method will do. Since HST is higher resolution and less affected by blending, we use it for detection but we also run detection on the HSC image to calculate the background RMS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ones_like() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n * (Tensor input, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Tensor input, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-272a9372dc7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mcatalog_hsc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbg_rms_hsc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeCatalog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_hsc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mweights_hst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_hst\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbg_rms_hst\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mweights_hsc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_hsc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbg_rms_hsc\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git_checkouts\\scarlet\\scarlet\\numeric\\torch\\__init__.py\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mintercepted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunc_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_subclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMyTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ones_like() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n * (Tensor input, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Tensor input, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "import sep\n",
    "def makeCatalog(img, lvl = 4):\n",
    "    if img.ndim == 3:\n",
    "        detect = img.mean(axis=0) # simple average for detection\n",
    "    else:\n",
    "        detect = img\n",
    "        \n",
    "    bkg = sep.Background(detect)\n",
    "    catalog = sep.extract(detect, lvl, err=bkg.globalrms)\n",
    "    if img.ndim == 3:\n",
    "        bg_rms = np.array([sep.Background(band).globalrms for band in img])\n",
    "    else:\n",
    "        bg_rms =  sep.Background(detect).globalrms\n",
    "    return catalog, bg_rms\n",
    "\n",
    "catalog_hst, bg_rms_hst = makeCatalog(data_hst, 4)\n",
    "catalog_hsc, bg_rms_hsc = makeCatalog(data_hsc, 4)\n",
    "\n",
    "weights_hst = np.ones_like(data_hst) / (bg_rms_hst**2)[:, None, None]\n",
    "weights_hsc = np.ones_like(data_hsc) / (bg_rms_hsc**2)[:, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can visualize both the multiband HSC and single band HST images in their native resolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\git_checkouts\\scarlet\\scarlet\\numeric\\torch\\__init__.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m  \u001b[1;31m# for numpy types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.dtype' object has no attribute '__name__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-843ac05245e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mYo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwcs_hsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwcs_world2pix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Map the HSC image to RGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mimg_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscarlet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_rgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_hsc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhsc_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m# Apply Asinh to the HST data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mhst_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscarlet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_rgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_hst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhst_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git_checkouts\\scarlet\\scarlet\\display.py\u001b[0m in \u001b[0;36mimg_to_rgb\u001b[1;34m(img, filter_weights, fill_value, norm)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[0mrgb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0muint8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \"\"\"\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[0mRGB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_to_channel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearMapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git_checkouts\\scarlet\\scarlet\\display.py\u001b[0m in \u001b[0;36mimg_to_channel\u001b[1;34m(img, filter_weights, fill_value)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mfilter_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# TODO: Numpy can multiply arrays of different dtypes, but PyTorch cannot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0mfilter_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# map bands onto RGB channels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git_checkouts\\scarlet\\scarlet\\numeric\\torch\\__init__.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 \u001b[1;32massert\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'torch.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'torch.float32'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'float'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'torch.float64'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'double'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a color mapping for the HSC image\n",
    "hsc_norm = AsinhMapping(minimum=-1, stretch=2, Q=10)\n",
    "hst_norm = AsinhMapping(minimum=-1, stretch=10, Q=5)\n",
    "\n",
    "# Get the source coordinates from the HST catalog\n",
    "xo,yo = catalog_hst['x'], catalog_hst['y']\n",
    "xi,yi = catalog_hsc['x'], catalog_hsc['y']\n",
    "# Convert the HST coordinates to the HSC WCS\n",
    "ra, dec = wcs_hst.wcs_pix2world(yo,xo,0)\n",
    "Yo,Xo, l = wcs_hsc.wcs_world2pix(ra, dec, 0, 0)\n",
    "# Map the HSC image to RGB\n",
    "img_rgb = scarlet.display.img_to_rgb(data_hsc, norm=hsc_norm)\n",
    "# Apply Asinh to the HST data\n",
    "hst_img = scarlet.display.img_to_rgb(data_hst, norm=hst_norm)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_rgb)\n",
    "plt.plot(Xo,Yo, 'o')\n",
    "plt.plot(xi,yi, 'o')\n",
    "plt.subplot(122)\n",
    "plt.imshow(hst_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Frame and Observations\n",
    "\n",
    "Unlike the single resolution examples, we now have two different instruments with different pixel resolutions, so we need two different observations. Since the HST image is at a much higher resolution, we define our model `Frame` to use the HST PSF and the HST resolution. Because there is no resampling between the model frame and the HST observation, we can use the default `Observation` class for the HST data. The HSC images have lower resolution, so we need to resample the models to this frame, and that's done by `LowResObservation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the frame using the HST PSF and WCS\n",
    "channels = channels_hsc + channels_hst\n",
    "shape = (len(channels), n1,n2)\n",
    "frame = scarlet.Frame(shape, wcs=wcs_hst, psf=psf_hst, channels=channels)\n",
    "\n",
    "# define two observation packages and match to frame\n",
    "obs_hst = scarlet.Observation(data_hst, wcs=wcs_hst, psf=psf_hst, channels=channels_hst, weights=weights_hst).match(frame)\n",
    "obs_hsc = scarlet.LowResObservation(data_hsc,  wcs=wcs_hsc, psf=psf_hsc, channels=channels_hsc, weights=weights_hsc)\n",
    "%time obs_hsc.match(frame)\n",
    "\n",
    "# Keep the order of the observations consistent with the `channels` parameter\n",
    "# This implementation is a bit of a hack and will be refined in the future\n",
    "obs = [obs_hsc, obs_hst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Sources and Blend\n",
    "\n",
    "We expect all sources to be galaxies, so we initialized them as `ExtendedSources`. Because the initialization takes a list of observations, we set the `obs_idx` argument to state which observation in the list of observations is used to initialize the morphology.\n",
    "\n",
    "`Blend` will hold a list of all sources and *all* observations to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    scarlet.ExtendedSource(frame, (ra[i], dec[i]), obs, \n",
    "                           symmetric=False, \n",
    "                           monotonic=True, \n",
    "                           obs_idx=1)\n",
    "    for i in range(ra.size)\n",
    "]\n",
    "\n",
    "blend = scarlet.Blend(sources, obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Initial guess\n",
    "\n",
    "Let's compare the initial guess of the model in both model frame and HSC observation frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and calculate the residual\n",
    "model = blend.get_model()\n",
    "\n",
    "%time obs_hsc.render(model)\n",
    "model_lr = obs_hsc.render(model)\n",
    "init_rgb = scarlet.display.img_to_rgb(model[:-1], norm=hsc_norm)\n",
    "init_rgb_lr = scarlet.display.img_to_rgb(model_lr, norm=hsc_norm)\n",
    "residual_lr = data_hsc - model_lr\n",
    "# Trim the bottom source not part of the blend from the image\n",
    "residual_lr_rgb = scarlet.display.img_to_rgb(residual_lr[:,:-5])\n",
    "\n",
    "# Get the HR residual\n",
    "residual_hr = (data_hst - obs_hst.render(model))[0]\n",
    "vmax = residual_hr.max()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(231)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"HSC data\")\n",
    "plt.subplot(235)\n",
    "plt.imshow(init_rgb)\n",
    "plt.title(\"HighRes Model\")\n",
    "plt.subplot(232)\n",
    "plt.imshow(init_rgb_lr)\n",
    "plt.title(\"LowRes Model\")\n",
    "plt.subplot(236)\n",
    "plt.imshow(residual_hr, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar(fraction=.045)\n",
    "plt.title(\"HST residual\")\n",
    "plt.subplot(233)\n",
    "plt.imshow(residual_lr_rgb)\n",
    "plt.title(\"HSC residual\")\n",
    "plt.subplot(234)\n",
    "plt.imshow(hst_img)\n",
    "plt.colorbar(fraction=.045)\n",
    "plt.title('HST data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time blend.fit(10)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Model\n",
    "First we load the model for the entire blend and its residual. Then we display the model using the same $sinh^{-1}$ stretch as the full image and a linear stretch for the residual to see the improvement from our initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = blend.get_model()\n",
    "model_hr = obs_hst.render(model)\n",
    "model_lr = obs_hsc.render(model)\n",
    "\n",
    "rgb = scarlet.display.img_to_rgb(model[:-1], norm=hsc_norm)\n",
    "rgb_lr = scarlet.display.img_to_rgb(model_lr, norm=hsc_norm)\n",
    "residual_lr = data_hsc - model_lr\n",
    "\n",
    "# Trim the bottom source not part of the blend from the image\n",
    "residual_lr_rgb = scarlet.display.img_to_rgb(residual_lr[:,:-5], norm=hsc_norm)\n",
    "\n",
    "# Get the HR residual\n",
    "residual_hr = (data_hst - model_hr)[0]\n",
    "vmax = residual_hr.max()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(231)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"HSC data\")\n",
    "plt.subplot(235)\n",
    "plt.imshow(rgb)\n",
    "plt.title(\"HST Model\")\n",
    "plt.subplot(232)\n",
    "plt.imshow(rgb_lr)\n",
    "plt.title(\"HSC Model\")\n",
    "plt.subplot(236)\n",
    "plt.imshow(residual_hr, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar(fraction=.045)\n",
    "plt.title(\"HST residual\")\n",
    "plt.subplot(233)\n",
    "plt.imshow(residual_lr_rgb)\n",
    "plt.title(\"HSC residual\")\n",
    "plt.subplot(234)\n",
    "plt.imshow(hst_img)\n",
    "plt.title('HST data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "It can also be useful to view the model for each source. For each source we extract the portion of the image contained in the sources bounding box, the true simulated source flux, and the model of the source, scaled so that all of the images have roughly the same pixel scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_truth = False\n",
    "axes = 2\n",
    "\n",
    "for k,src in enumerate(blend.sources):\n",
    "    print('source number ', k)\n",
    "    # Get the model for a single source\n",
    "    model = src.get_model()\n",
    "    model_lr = obs_hsc.render(model)\n",
    "    \n",
    "    # Display the low resolution image and residuals\n",
    "    img_lr_rgb = scarlet.display.img_to_rgb(model_lr, norm = hsc_norm)\n",
    "    res = data_hsc-model_lr\n",
    "    res_rgb = scarlet.display.img_to_rgb(res, norm = hsc_norm)\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    \n",
    "    plt.subplot(331)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.plot(Xo[k],Yo[k], 'x', markersize = 10)\n",
    "    plt.title(\"HSC Data\")\n",
    "    plt.subplot(332)\n",
    "    plt.imshow(img_lr_rgb)\n",
    "    plt.title(\"LR Model\")\n",
    "    plt.subplot(333)\n",
    "    plt.imshow(res_rgb)\n",
    "    plt.title(\"LR Data - Model\")\n",
    "    \n",
    "    img_hr = obs_hst.render(model)\n",
    "    res = data_hst-img_hr[-1]\n",
    "    vmax = res.max()\n",
    "    \n",
    "    plt.subplot(334)\n",
    "    plt.imshow(data_hst[0], cmap='gist_stern')\n",
    "    plt.plot(xo[k],yo[k], 'o', markersize = 5)\n",
    "    plt.title(\"HST Data\")\n",
    "    plt.subplot(335)\n",
    "    plt.imshow(img_hr[-1])\n",
    "    plt.title(\"HR Model\")\n",
    "    plt.subplot(336)\n",
    "    plt.imshow(res[0], cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    plt.title(\"HR Data - Model\")\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
